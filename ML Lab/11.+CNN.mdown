# lec11-1 CNN 만들기
------------------------------------------------
![d](https://3.bp.blogspot.com/-UhSd7zIn4i4/V7aoqShB-XI/AAAAAAAAIGo/Vkvb45KN9-8aqZEDEUjhWaqjn9HBm7PyACK4B/s400/ScreenShot_20160811153954.png)

전체적인 cnn과정을 보면 위와 같다.
전체 사진 하나에서 아래와 같이 픽셀을 줄이면서 레이어를 거치면서 학습한다.

![d](https://3.bp.blogspot.com/-7oh4VI6-iV4/V7apLxX_YZI/AAAAAAAAIGw/Nf2HA2pdedQEzPdrZs0N-dlq9GX0SV-oQCK4B/s400/ScreenShot_20160811153954.png)
 
위와 같이 어느 부분의 픽셀을 하나의 숫자로 만들어가면서 전체 픽셀을 줄여간다.
그리고 ReLU를 거치고 다음 레이어에 보낸다.
5x5x3 픽셀을 전체 이미지를 다 훑으면서 픽셀을 줄이면 아래와 같은 과정을 통해 28x28x6이 된다.

![d](https://2.bp.blogspot.com/-gANR0kue-8E/V7ap61a6EZI/AAAAAAAAIHA/WzQA_lyEKgA590R99tHS0D-wfQC42Z1xwCK4B/s400/ScreenShot_20160811153954.png)

필터를 통해 픽셀을 줄여나갈 때, 딱 정수로 떨어지지 않는다면 패딩을 통해 맞출 수 있다.

![d](https://3.bp.blogspot.com/-5MGlmUFG5EM/V7aqvZ3BSsI/AAAAAAAAIHI/__NSYu2L-D8ef5PYX6O9wb8azxDt7MEmgCK4B/s400/ScreenShot_20160811153954.png)

위의 공식에서 N은 전체 이미지의 가로 혹은 세로 픽셀의 갯수이고
F는 필터 픽셀의 가로 혹은 세로 픽셀의 갯수이다.
stride는 필터 픽셀이 몇 칸씩 움직이며 필터링을 할 것인가 정하는 것이다.

# lec11-2: ConvNet Max pooling 과 Full Network
-------------------------------------------------------
처음에 봤던 cnn의 전체 과정에서 pooling이라는 과정을 보았다.

![d](https://4.bp.blogspot.com/-aAfaRJn3OlA/V7arm95sY0I/AAAAAAAAIHU/EZ5af-DuiVwzIWyTVTWotVdqyRbj0ejOwCK4B/s400/ScreenShot_20160811153954.png)

풀링은 이미지를 압축하는 과정이다. 풀링 가운데에 max pooling이라는 방법이 있다.

![d](https://3.bp.blogspot.com/-1nKtSwfUXk4/V7ar8jGA0FI/AAAAAAAAIHg/e9zpX9iVUEICvfbG5SfhTU_3dkcCSrtXgCK4B/s400/ScreenShot_20160811153954.png)

위와 같이 규칙을 통해 특정 범위의 픽셀 중 가장 큰 픽셀로 이미지를 압축한다.

#lec11-3 ConvNet의 활용예
-------------------------------------------------------
![d](https://4.bp.blogspot.com/-f2IBklODFVg/V7atsyJY8bI/AAAAAAAAIHs/l2-ERMnA1KknAgACvGXvx2MujbPP_5haQCK4B/s400/ScreenShot_20160811153954.png)

이미지넷에서 정확도를 확 올린 Alexnet의 딥러닝이다.
이때까지 배운 것을 다 사용했다.
ReLU도 처음 활용된 예라고 한다.
총 8개의 레이어를 사용하여 앙상블을 했다.
15프로의 오류율을 보였다.

![d](https://1.bp.blogspot.com/-QQttdtkKV_o/V7auJOmMtnI/AAAAAAAAIH0/5iUJ9ToVR-Iklo1Ypwk7Lsr_AawO2d2XQCK4B/s400/ScreenShot_20160811153954.png)

이번에는 최고의 에러율을 보였던 ResNet이다.
사람의 오류율이 5프로인데 이 딥러닝은 3.6프로의 오류율을 보였다.
이 딥러닝은 152개의 레이어를 사용했다.

![d](https://1.bp.blogspot.com/-WclHZOqwBsU/V7aukLu8NOI/AAAAAAAAIH8/3O8CQA4fmKsZo3fj0zdgXUpiOw8ucc6rQCK4B/s400/ScreenShot_20160811153954.png)

이 딥러닝의 특이점은 전 레이어의 값이 갑자기 다다음 레이어로 뛰어넘어 연산된다는 것이다. 왜 잘되는 지는 설명하지 못하지만 제일 높은 정확도를 보였다.




